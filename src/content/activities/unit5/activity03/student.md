# Actividad 3
## Diseño Preliminar de la Experiencia Interactiva en el Concierto Instrumental
Mi proyecto busca transformar la experiencia de los conciertos instrumentales a través de una visualización interactiva en tiempo real. La audiencia podrá ver partículas generadas por las notas musicales en una pantalla o proyección y modificar sus características (como color y tamaño) desde sus dispositivos móviles.

## Fases de la Experiencia
### Antes de la Experiencia
Antes del concierto, los asistentes podrán descargar una aplicación web en sus dispositivos móviles o escanear un código QR para acceder a la plataforma de interacción. También recibirán una breve explicación sobre cómo su participación influirá en la visualización en pantalla. Esta introducción servirá para generar expectativa y emoción sobre la experiencia.

### Durante la Experiencia
A medida que los músicos toquen sus instrumentos, los sonidos generarán partículas visuales en tiempo real en la pantalla principal del evento. Los asistentes podrán interactuar con estas partículas desde sus dispositivos móviles, cambiando su color, tamaño o intensidad en función de la emoción o sensación que la música les transmita. El sistema capturará los datos de la música y la interacción de los usuarios para generar una visualización fluida y envolvente.

### Después de la Experiencia
Una vez finalizado el concierto, la aplicación mostrará un resumen visual de la participación del público, permitiéndoles ver cómo sus interacciones influyeron en el espectáculo. También se podría generar un video de la visualización como recuerdo. Además, los datos recopilados podrían utilizarse para mejorar futuras experiencias interactivas.

## Conexión de la Narrativa con la Experiencia
La música tiene la capacidad de evocar emociones y transportar a las personas a diferentes estados de ánimo. Esta experiencia busca hacer tangible esa conexión emocional a través de visualizaciones dinámicas. Los asistentes no solo escucharán la música, sino que también podrán "verla" y "tocar" su representación digital, creando una relación más profunda con la interpretación instrumental.

### Dispositivos Utilizados
**Dispositivo principal:**  Un computador con software de visualización conectado a una pantalla o proyector.

**Dos dispositivos externos:** Micrófonos y sensores que capturan la música en tiempo real y transforman las notas en partículas visuales.

**Tercer dispositivo:** Teléfonos móviles de los asistentes, que servirán como control remoto para modificar las partículas.

## Datos Capturados
**Frecuencia y amplitud de las notas musicales:** Para generar partículas en tiempo real.

**Interacciones del público:** Datos sobre color, tamaño y modificaciones en las partículas.

**Tiempo y tipo de interacción:** Para analizar la respuesta de los asistentes y su impacto en la experiencia visual.

## Conexión de los Datos con el Concepto y la Narrativa
Cada sonido tiene un impacto visual y cada persona puede influir en esa representación. Así como la música se adapta y evoluciona con el artista, la visualización se transformará con la interacción del público. Esto refuerza la idea de que la música no solo se escucha, sino que también se vive y se siente de forma única para cada persona.

## Control Remoto y Tipo de Interacción
El público usará sus teléfonos móviles para interactuar con la visualización a través de una interfaz sencilla. Podrán:

Cambiar el color de las partículas.

Modificar el tamaño de las partículas.

Ajustar la intensidad de la visualización.

Esto permitirá que cada usuario tenga una influencia en la obra visual, creando un concierto verdaderamente participativo.

## Contenido en Tiempo Real
Generación de partículas basadas en la música.

Modificación de la visualización en respuesta a la interacción del público.

Visualización dinámica y envolvente proyectada en pantalla grande.

![image](https://github.com/user-attachments/assets/e21c3d81-f646-4dd2-aa6d-d1d8064daef6)
